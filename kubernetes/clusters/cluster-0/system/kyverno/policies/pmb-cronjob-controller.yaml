---
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: pmb-cronjob-controller
  annotations:
    policies.kyverno.io/title: pmb CronJob controller
    policies.kyverno.io/subject: Deployment,StatefulSet
    policies.kyverno.io/description: >-
      This policy generates a backup CronJob for
      Deployments, StatefulSets
spec:
  mutateExistingOnPolicyUpdate: true
  generateExistingOnPolicyUpdate: true
  rules:
    - name: create-cronjob
      match:
        any:
          - resources:
              kinds:
                - Deployment
                - StatefulSet
              annotations:
                pmb.bjw-s.dev/volume: "*"

      context:
        - name: appName
          variable:
            jmesPath: "request.object.metadata.annotations.\"pmb.bjw-s.dev/app\" || request.object.metadata.annotations.\"app.kubernetes.io/name\" || request.object.metadata.name"
        - name: volume
          variable:
            jmesPath: "request.object.metadata.annotations.\"pmb.bjw-s.dev/volume\""
        - name: claimName
          variable:
            jmesPath: "(request.object.spec.template.spec.volumes[? @.name == '{{ volume }}'] | [0].persistentVolumeClaim.claimName) || \"\""

      generate:
        synchronize: true
        apiVersion: batch/v1
        kind: CronJob
        name: "{{ appName }}-backup"
        namespace: "{{request.object.metadata.namespace}}"
        data:
          metadata:
            ownerReferences:
              - apiVersion: "{{request.object.apiVersion}}"
                kind: "{{request.object.kind}}"
                name: "{{request.object.metadata.name}}"
                uid: "{{request.object.metadata.uid}}"
          spec:
            schedule: "@daily"
            suspend: false
            concurrencyPolicy: Forbid
            successfulJobsHistoryLimit: 0
            failedJobsHistoryLimit: 2
            jobTemplate:
              spec:
                ttlSecondsAfterFinished: 3600
                template:
                  spec:
                    automountServiceAccountToken: false
                    restartPolicy: OnFailure
                    initContainers:
                      # Stagger jobs to run randomly within X seconds to avoid bringing down all apps at once
                      - name: wait
                        image: ghcr.io/onedr0p/alpine:3.16.1@sha256:ed7edf90c1e7df516ff37267841a17d0bedf7ef873f8f81bb3ddf06b3a464d06
                        command: ["/scripts/sleep.sh"]
                        args: ["1", "900"]

                    containers:
                      - name: backup
                        image: ghcr.io/onedr0p/kopia:0.11.3@sha256:db13525a2779b77e4c1db2e14470a369a2c8c9ebac575706c1141f0a786c7f62
                        env:
                          - name: KOPIA_CACHE_DIRECTORY
                            value: /data/backups/{{ appName }}/cache
                          - name: KOPIA_LOG_DIR
                            value: /data/backups/{{ appName }}/logs
                          - name: KOPIA_PASSWORD
                            value: "${KOPIA_PASSWORD}"
                        command:
                          - /bin/bash
                          - -c
                          - |-
                            printf "\e[1;32m%-6s\e[m\n" "[01/09] Create repo ..."          && [[ ! -f /data/backups/kopia.repository.f ]] && kopia repository create filesystem --path=/data/backups
                            printf "\e[1;32m%-6s\e[m\n" "[02/09] Connect to repo ..."      && kopia repo connect filesystem --path=/data/backups --override-hostname=cluster --override-username=root
                            printf "\e[1;32m%-6s\e[m\n" "[03/09] Set policies ..."         && kopia policy set /{{ appName }} --compression=zstd --keep-latest 14 --keep-hourly 0 --keep-daily 7 --keep-weekly 2 --keep-monthly 0 --keep-annual 0
                            printf "\e[1;32m%-6s\e[m\n" "[04/09] Freeze config vol ..."    && fsfreeze -f /{{ appName }}
                            printf "\e[1;32m%-6s\e[m\n" "[05/09] Back up config vol ..."   && kopia snap create /{{ appName }}
                            printf "\e[1;32m%-6s\e[m\n" "[06/09] Unfreeze config vol ..."  && fsfreeze -u /{{ appName }}
                            printf "\e[1;32m%-6s\e[m\n" "[07/09] List snaps ..."           && kopia snap list /{{ appName }}
                            printf "\e[1;32m%-6s\e[m\n" "[08/09] Show stats ..."           && kopia content stats
                            printf "\e[1;32m%-6s\e[m\n" "[09/09] Disconnect from repo ..." && kopia repo disconnect
                        securityContext:
                          privileged: true
                        volumeMounts:
                          - name: appdata
                            mountPath: "/{{ appName }}"
                          - name: backup
                            mountPath: /data/backups
                    volumes:
                      - name: appdata
                        persistentVolumeClaim:
                          claimName: "{{ claimName }}"
                      - name: backup
                        nfs:
                          server: "${NAS_ADDRESS}"
                          path: "/volume1/Backup/Kubernetes/Kopia"
                    affinity:
                      podAffinity:
                        requiredDuringSchedulingIgnoredDuringExecution:
                          - labelSelector:
                              matchExpressions: "{{ items(request.object.spec.selector.matchLabels, 'key', 'value')[].{key: key, operator: 'In', values: [value] } }}"
                            topologyKey: kubernetes.io/hostname
